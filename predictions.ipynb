{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classifier comparison\n",
    "\n",
    "\n",
    "A comparison of a several classifiers in scikit-learn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Code source: Gaël Varoquaux\n",
    "#              Andreas Müller\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "#from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and pre-processing data\n",
    "\n",
    "To begin with, I replaced NA's with zeros. \n",
    "\n",
    "Later, I will see how many features were mostly \"NA\". If they are not important, I will probably drop them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "trainX = [] \n",
    "with open(\"/home/lu/Documents/School/81_machine_learning/HW3/HW3/trainingData.txt\", 'r') as rp: \n",
    "    for line in rp.read().split(\"\\n\"): \n",
    "        row = line.split(\"\\t\") \n",
    "        i = 0 \n",
    "        for cell in row: \n",
    "            try: \n",
    "                row[i] = float(cell)\n",
    "            except ValueError: \n",
    "                row[i] = 0 \n",
    "            i+=1 \n",
    "        trainX.append(row)\n",
    "        \n",
    "trainY = [] \n",
    "with open(\"/home/lu/Documents/School/81_machine_learning/HW3/HW3/trainingTruth.txt\", 'r') as rp: \n",
    "    for line in rp.read().split(\"\\n\"): \n",
    "        trainY.append(line)\n",
    "        \n",
    "testX = [] \n",
    "with open(\"/home/lu/Documents/School/81_machine_learning/HW3/HW3/testData.txt\", 'r') as rp: \n",
    "    for line in rp.read().split(\"\\n\"): \n",
    "        row = line.split(\"\\t\") \n",
    "        i = 0 \n",
    "        for cell in row: \n",
    "            try: \n",
    "                row[i] = float(cell)\n",
    "            except ValueError: \n",
    "                row[i] = 0 \n",
    "            i+=1 \n",
    "        testX.append(row)\n",
    "\n",
    "blindX = [] \n",
    "with open(\"/home/lu/Documents/School/81_machine_learning/HW3/HW3/blindData.txt\", 'r') as rp: \n",
    "    for line in rp.read().split(\"\\n\"): \n",
    "        row = line.split(\"\\t\") \n",
    "        i = 0 \n",
    "        for cell in row: \n",
    "            try: \n",
    "                row[i] = float(cell)\n",
    "            except ValueError: \n",
    "                row[i] = 0 \n",
    "            i+=1 \n",
    "        blindX.append(row[0:334])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Split data into training and tests sets \n",
    "### For some reason, I always have a few extra lines that I have to truncate off of my data arrays\n",
    "### I think it comes from my file-parsing \n",
    "\n",
    "arrayX = np.array(trainX[0:17377])\n",
    "arrayY = np.array(trainY[0:17377])\n",
    "arrayTest = np.array(testX[0:8179])\n",
    "arrayBlind = np.array(blindX[0:20049])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(arrayX, arrayY, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier | Score on Test | Score on Train \n",
      "--- | --- | --- | \n",
      "DecisionTree_old |0.462|0.503\n",
      "['0.097', '0.137', '0.655', '0.111', 3]\n",
      "['0.148', '0.282', '0.379', '0.191', 3]\n",
      "['0.097', '0.137', '0.655', '0.111', 3]\n",
      "['0.533', '0.196', '0.123', '0.147', 1]\n",
      "['0.091', '0.254', '0.478', '0.177', 3]\n",
      "['0.410', '0.300', '0.150', '0.140', 1]\n",
      "['0.097', '0.137', '0.655', '0.111', 3]\n",
      "['0.097', '0.137', '0.655', '0.111', 3]\n",
      "['0.129', '0.141', '0.561', '0.168', 3]\n",
      "['0.574', '0.157', '0.151', '0.118', 1]\n",
      "RandomForest_old |0.447|0.485\n",
      "['0.380', '0.215', '0.249', '0.155', 1]\n",
      "['0.311', '0.221', '0.316', '0.152', 3]\n",
      "['0.255', '0.194', '0.431', '0.120', 3]\n",
      "['0.337', '0.180', '0.326', '0.157', 1]\n",
      "['0.306', '0.207', '0.348', '0.139', 3]\n",
      "['0.326', '0.238', '0.275', '0.161', 1]\n",
      "['0.357', '0.207', '0.300', '0.137', 1]\n",
      "['0.222', '0.352', '0.286', '0.140', 2]\n",
      "['0.317', '0.224', '0.303', '0.156', 1]\n",
      "['0.276', '0.209', '0.361', '0.155', 3]\n",
      "Logit l=4 |0.758|0.792\n",
      "['0.025', '0.024', '0.564', '0.388', 3]\n",
      "['0.000', '0.140', '0.664', '0.196', 3]\n",
      "['0.004', '0.113', '0.862', '0.021', 3]\n",
      "['0.892', '0.022', '0.024', '0.062', 1]\n",
      "['0.000', '0.418', '0.527', '0.055', 3]\n",
      "['0.681', '0.309', '0.001', '0.009', 1]\n",
      "['0.147', '0.330', '0.499', '0.024', 3]\n",
      "['0.004', '0.575', '0.148', '0.274', 2]\n",
      "['0.770', '0.038', '0.039', '0.152', 1]\n",
      "['0.012', '0.313', '0.629', '0.046', 3]\n",
      "GaussianNB |0.771|0.796\n",
      "['0.002', '0.001', '0.933', '0.064', 3]\n",
      "['0.000', '0.001', '0.988', '0.012', 3]\n",
      "['0.000', '0.000', '1.000', '0.000', 3]\n",
      "['0.974', '0.000', '0.000', '0.026', 1]\n",
      "['0.000', '0.030', '0.961', '0.009', 3]\n",
      "['0.999', '0.001', '0.000', '0.000', 1]\n",
      "['0.012', '0.016', '0.941', '0.032', 3]\n",
      "['0.000', '0.813', '0.002', '0.185', 2]\n",
      "['0.915', '0.056', '0.000', '0.029', 1]\n",
      "['0.000', '0.006', '0.993', '0.000', 3]\n",
      "Nearest Neighbors |0.606|0.750\n",
      "['0.000', '0.000', '0.667', '0.333', 3]\n",
      "['0.000', '0.000', '1.000', '0.000', 3]\n",
      "['0.000', '0.333', '0.667', '0.000', 3]\n",
      "['0.333', '0.333', '0.333', '0.000', 1]\n",
      "['0.000', '0.333', '0.667', '0.000', 3]\n",
      "['1.000', '0.000', '0.000', '0.000', 1]\n",
      "['0.333', '0.000', '0.000', '0.667', 4]\n",
      "['0.000', '0.000', '0.667', '0.333', 3]\n",
      "['0.667', '0.000', '0.333', '0.000', 1]\n",
      "['0.000', '0.000', '1.000', '0.000', 3]\n",
      "Rand Forest |0.613|0.772\n",
      "['0.246', '0.192', '0.410', '0.152', 3]\n",
      "['0.089', '0.150', '0.592', '0.170', 3]\n",
      "['0.093', '0.196', '0.583', '0.128', 3]\n",
      "['0.524', '0.162', '0.177', '0.137', 1]\n",
      "['0.107', '0.163', '0.608', '0.121', 3]\n",
      "['0.477', '0.211', '0.176', '0.136', 1]\n",
      "['0.166', '0.210', '0.382', '0.242', 3]\n",
      "['0.269', '0.250', '0.317', '0.164', 3]\n",
      "['0.465', '0.185', '0.222', '0.129', 1]\n",
      "['0.181', '0.203', '0.498', '0.118', 3]\n",
      "Logit |0.764|0.793\n",
      "['0.015', '0.013', '0.621', '0.351', 3]\n",
      "['0.000', '0.123', '0.681', '0.196', 3]\n",
      "['0.003', '0.093', '0.886', '0.019', 3]\n",
      "['0.903', '0.019', '0.017', '0.061', 1]\n",
      "['0.000', '0.393', '0.558', '0.049', 3]\n",
      "['0.683', '0.308', '0.001', '0.008', 1]\n",
      "['0.149', '0.332', '0.494', '0.024', 3]\n",
      "['0.003', '0.601', '0.109', '0.287', 2]\n",
      "['0.778', '0.039', '0.023', '0.160', 1]\n",
      "['0.007', '0.215', '0.741', '0.036', 3]\n",
      "RBF SVM |0.329|1.000\n",
      "['0.325', '0.224', '0.300', '0.150', 1]\n",
      "['0.460', '0.319', '0.007', '0.214', 1]\n",
      "['0.460', '0.319', '0.007', '0.214', 1]\n",
      "['0.009', '0.329', '0.441', '0.221', 3]\n",
      "['0.460', '0.319', '0.007', '0.214', 1]\n",
      "['0.325', '0.224', '0.300', '0.150', 1]\n",
      "['0.382', '0.264', '0.354', '0.000', 1]\n",
      "['0.325', '0.224', '0.300', '0.150', 1]\n",
      "['0.325', '0.224', '0.300', '0.150', 1]\n",
      "['0.325', '0.224', '0.300', '0.150', 1]\n",
      "Logit l=2 |0.761|0.793\n",
      "['0.018', '0.017', '0.599', '0.366', 3]\n",
      "['0.000', '0.130', '0.674', '0.196', 3]\n",
      "['0.003', '0.101', '0.877', '0.019', 3]\n",
      "['0.898', '0.020', '0.020', '0.061', 1]\n",
      "['0.000', '0.403', '0.546', '0.051', 3]\n",
      "['0.682', '0.308', '0.001', '0.008', 1]\n",
      "['0.148', '0.331', '0.497', '0.024', 3]\n",
      "['0.004', '0.590', '0.125', '0.282', 2]\n",
      "['0.775', '0.039', '0.029', '0.157', 1]\n",
      "['0.009', '0.253', '0.699', '0.040', 3]\n",
      "Linear SVC |0.757|0.820\n",
      "['0.068', '0.036', '0.759', '0.137', 3]\n",
      "['0.002', '0.058', '0.726', '0.214', 3]\n",
      "['0.007', '0.052', '0.912', '0.029', 3]\n",
      "['0.827', '0.054', '0.021', '0.097', 1]\n",
      "['0.002', '0.122', '0.791', '0.086', 3]\n",
      "['0.740', '0.234', '0.004', '0.023', 1]\n",
      "['0.180', '0.248', '0.471', '0.101', 3]\n",
      "['0.027', '0.384', '0.147', '0.441', 4]\n",
      "['0.701', '0.136', '0.042', '0.121', 1]\n",
      "['0.046', '0.126', '0.733', '0.095', 3]\n",
      "Adaboost |0.621|0.650\n",
      "['0.250', '0.245', '0.260', '0.246', 3]\n",
      "['0.243', '0.250', '0.256', '0.250', 3]\n",
      "['0.242', '0.247', '0.258', '0.253', 3]\n",
      "['0.257', '0.252', '0.236', '0.255', 1]\n",
      "['0.231', '0.251', '0.265', '0.253', 3]\n",
      "['0.270', '0.250', '0.234', '0.246', 1]\n",
      "['0.252', '0.248', '0.259', '0.241', 3]\n",
      "['0.237', '0.261', '0.253', '0.250', 2]\n",
      "['0.248', '0.248', '0.252', '0.252', 4]\n",
      "['0.243', '0.249', '0.265', '0.244', 3]\n",
      "QDA |0.665|1.000\n",
      "['0.000', '0.000', '1.000', '0.000', 3]\n",
      "['0.000', '0.000', '1.000', '0.000', 3]\n",
      "['0.000', '0.000', '1.000', '0.000', 3]\n",
      "['1.000', '0.000', '0.000', '0.000', 1]\n",
      "['0.000', '0.000', '1.000', '0.000', 3]\n",
      "['1.000', '0.000', '0.000', '0.000', 1]\n",
      "['0.000', '0.000', '0.000', '1.000', 4]\n",
      "['0.875', '0.125', '0.000', '0.000', 1]\n",
      "['0.000', '1.000', '0.000', '0.000', 2]\n",
      "['0.000', '0.000', '1.000', '0.000', 3]\n",
      "DecisionTree |0.471|0.517\n",
      "['0.128', '0.219', '0.526', '0.127', 3]\n",
      "['0.082', '0.313', '0.395', '0.210', 3]\n",
      "['0.064', '0.143', '0.667', '0.127', 3]\n",
      "['0.548', '0.160', '0.150', '0.142', 1]\n",
      "['0.064', '0.143', '0.667', '0.127', 3]\n",
      "['0.674', '0.157', '0.085', '0.085', 1]\n",
      "['0.128', '0.219', '0.526', '0.127', 3]\n",
      "['0.128', '0.219', '0.526', '0.127', 3]\n",
      "['0.128', '0.224', '0.501', '0.147', 3]\n",
      "['0.548', '0.160', '0.150', '0.142', 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifiers = {\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(3),\n",
    "    \"Linear SVC\": SVC(kernel=\"linear\", C=0.5, probability=True),\n",
    "    \"RBF SVM\": SVC(gamma=2, C=1, probability=True),\n",
    "    \"DecisionTree_old\": DecisionTreeClassifier(max_depth=5), \n",
    "    \"RandomForest_old\": RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=20, random_state=0),\n",
    "    \"Rand Forest\": RandomForestClassifier(n_estimators=30, criterion='entropy', max_depth=20, min_samples_leaf=20, \n",
    "                           bootstrap=True, oob_score=False, random_state=0 ),\n",
    "    \"Adaboost\": AdaBoostClassifier(),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"Logit\": LogisticRegression(C=1), \n",
    "    \"Logit l=2\": LogisticRegression(C=0.5), \n",
    "    \"Logit l=4\": LogisticRegression(C=0.25),\n",
    "    \"QDA\": QuadraticDiscriminantAnalysis()\n",
    "}\n",
    "print(\"Classifier | Score on Test | Score on Train \")\n",
    "print(\"--- | --- | --- | \")\n",
    "\n",
    "\n",
    "import operator\n",
    "for name, classifier in  classifiers.items() : \n",
    "    clf=classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    ## Sanity check by predicting what is in the trainingTruth.txt file \n",
    "    prob_array = clf.predict_proba(arrayX[0:10])\n",
    "    row = [\n",
    "        clf.score(X_test, y_test) ,clf.score(X_train, y_train), #comparing test and training on 4/6 split\n",
    "         ]\n",
    "    print( \"%s |\"%name + \"|\".join([\"%.3f\" % x for x in row]) )\n",
    "    \n",
    "    for row in prob_array: \n",
    "        index, value = max(enumerate(row), key=operator.itemgetter(1))\n",
    "        print([\"%.3f\" % x for x in row] + [index+1] )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Predict using the best classifier we currently have\n",
    "\n",
    "From the classifier comparison notebook, the best model we currently have is the GaussianNaiveBayes. Let's create and train this classifier and then use it to predict probabilities and a label per observation in the testData.txt file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf=GaussianNB()\n",
    "clf.fit(arrayX, arrayY)\n",
    "\n",
    "prob_array = clf.predict_proba(arrayTest)\n",
    "\n",
    "with open('wang_ochoa_test_predictions.csv', 'w') as wp: \n",
    "    for row in prob_array: \n",
    "        index, value = max(enumerate(row), key=operator.itemgetter(1))\n",
    "        line_list = [\"%.3f\" % x for x in row] + [str(index+1)] \n",
    "        line_str = '\\t'.join(line_list)+'\\n'\n",
    "        wp.write(line_str)\n",
    "\n",
    "prob_array = clf.predict_proba(arrayBlind)\n",
    "\n",
    "with open('wang_ochoa_blind_predictions.csv', 'w') as wp: \n",
    "    for row in prob_array: \n",
    "        index, value = max(enumerate(row), key=operator.itemgetter(1))\n",
    "        line_list = [\"%.3f\" % x for x in row] + [str(index+1)] \n",
    "        line_str = '\\t'.join(line_list)+'\\n'\n",
    "        wp.write(line_str)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
